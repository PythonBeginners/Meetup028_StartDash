{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNISTでの機械学習ハンズオン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "機械学習について\n",
    "\n",
    "機械学習の種類としては大雑把に\n",
    "+ 深層学習 (Deep Learning) \n",
    "+ 強化学習\n",
    "+ ベイズ推定\n",
    "\n",
    "があげられます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ 画像処理\n",
    "    + 物体検知\n",
    "    + 物体認識 (分類とか)\n",
    "    + 画像生成 https://blogs.nvidia.com/blog/2019/03/18/gaugan-photorealistic-landscapes-nvidia-research/\n",
    "+ 自然言語処理\n",
    "    + 翻訳\n",
    "    + 文章理解\n",
    "    + 概要生成\n",
    "    + 文章生成\n",
    "+ 音声認識\n",
    "    + 文章に変換\n",
    "+ 数値データによる予測 \n",
    "    + 株の数値予測\n",
    "    + 競馬の予測\n",
    "    + 顧客予測\n",
    "\n",
    "それぞれでトレンドとされる技術が違うので勉強が必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "だいたいGoogle APIが提供してたりする。\n",
    "+ 分かち書きや重要単語, 係り受けなどを返すAPI\n",
    "https://cloud.google.com/natural-language/ \n",
    "\n",
    "+ みんな大好き Google 翻訳\n",
    "https://cloud.google.com/translate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ 深層学習 (物体検知 https://www.youtube.com/watch?v=tJnGiPGz-p8) \n",
    "+ 強化学習 (自動運転 https://www.youtube.com/watch?time_continue=27&v=SZYbEhLrvg4)\n",
    "+ ベイズ推定 (ベイズ推定でできること https://www.udemy.com/computervision/learn/lecture/297992#overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kerasで多層パーセプトロン（Multi-Layer Perceptron, MLP）を組んで手書き文字を判別してみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※このパートはPyDataOkinawa 第16回の資料を参考にしています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networkと呼ばれる技術で、\n",
    "\n",
    "色々派生した技術がありますが、大本の技術から触っていこうかなと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習をするなら、機械学習の知識についてよく知ってる上で、\n",
    "\n",
    "フレームワークがどのような動きをするかどうかを知ることが大事です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 必要なフレームワークのインストール\n",
    "# !pip install keras\n",
    "# !pip install tensorflow==2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのコンパイル\n",
    "+ 最適化手法の選択\n",
    "    + 通常はAdadeltaかAdam、もしくはSGD with Nesterov momentumでOK\n",
    "    + RNNならRMSpropが安定している\n",
    "    + 超複雑なネットワークを、大量のデータで学習させるときには極力小さな学習率でシンプルなSGD without momentumを用いるのが良かったりする。（validation errorの減少が止まったら学習率を半分にする）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== デフォルト設定で使う場合 ====\n",
    "# optimizerに全て小文字のストリングを渡すだけ（超カンタン！）\n",
    "# 例えば以下のような設定が使える\n",
    "# optimizer='sgd'\n",
    "# optimizer='adadelta'\n",
    "# optimizer='adam'\n",
    "# optimizer='rmsprop\n",
    "\n",
    "# ==== 好みに合わせて設定を変えたい場合 ====\n",
    "# まず、最適化手法のクラスを読み込む\n",
    "# from keras.optimizers import SGD, Adadelta, Adam, RMSprop\n",
    "# それらをインスタンス化してからoptimizer引数に渡す\n",
    "# 例）　SGD with Nesterov momentum を用いる場合\n",
    "# sgd_nesterov=SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss='categorical_crossentropy', # 損失関数（この量のパラメータ勾配で学習する）\n",
    "              optimizer='sgd', # 最適化手法（デフォルト設定）\n",
    "              #optimizer='rmsprop', # 最適化手法（デフォルト設定）\n",
    "              #optimizer=sgd_nesterov, # 最適化手法（お好み設定）\n",
    "              metrics=['accuracy'] # 評価指標\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON形式でモデルを保存\n",
    "json_string = model.to_json()\n",
    "open('./mnist_mlp_model.json', 'w').write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML形式でモデルを保存\n",
    "yaml_string = model.to_yaml()\n",
    "open('./mnist_mlp_model.yaml', 'w').write(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　初期ウエイトの保存\n",
    "model.save_weights('./mnist_mlp_init_weight.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの読み出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json, model_from_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON形式で保存されたモデルの呼び出し\n",
    "# json_string = open('./mnist_mlp_model.json', 'r').read()\n",
    "# model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML形式で保存されたモデルの呼び出し\n",
    "# yaml_string = open('./mnist_mlp_model.yaml', 'r').read()\n",
    "# model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータの読み出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('./mnist_mlp_init_weight.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手書き文字データセット（MNIST）の読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化用ライブラリの読み込み\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データを可視化（最初の５文字）\n",
    "fig, ax = plt.subplots(1, 5)\n",
    "\n",
    "for ii in range(5):\n",
    "    ax[ii].imshow(X_train[ii], cmap='gray')\n",
    "    ax[ii].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TensorBoardで学習の進捗状況をみる (今回は見ない)\n",
    "# tb_cb = keras.callbacks.TensorBoard(log_dir='/tmp/keras_mnist_mlp', histogram_freq=1)\n",
    "\n",
    "# バリデーションロスが下がれば、エポックごとにモデルを保存\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(filepath='./mnist_mlp_best_weight.hdf5', \n",
    "                                        monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# バリデーションロスが５エポック連続で上がったら、ランを打ち切る\n",
    "es_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "cbks = [cp_cb, es_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "# 学習を実行\n",
    "# 学習途中の損失関数の値などはhistory.historyに保存される。\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,   # 画像とラベルデータ\n",
    "                    batch_size=128, \n",
    "                    epochs=20,    # エポック数の指定\n",
    "                    verbose=1,     # ログ出力の指定. 0だとログが出ない\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    callbacks=cbks)\n",
    "toc = time.time()\n",
    "\n",
    "# 学習にかかった時間を表示\n",
    "print(\"Execution time: {0:.2f} [sec]\".format(toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベストなパラメータの呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./mnist_mlp_best_weight.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータに対する評価値\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test score:', score[0]) # 損失関数の値\n",
    "print('Test accuracy:', score[1]) # 精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].set_title('Training performance (Loss)')\n",
    "ax[0].plot(history.epoch, history.history['loss'], label='loss')\n",
    "ax[0].plot(history.epoch, history.history['val_loss'], label='val_loss')\n",
    "ax[0].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].set_title('Training performance (Accuracy)')\n",
    "ax[1].plot(history.epoch, history.history['accuracy'], label='accuracy')\n",
    "ax[1].plot(history.epoch, history.history['val_accuracy'], label='val_accuracy')\n",
    "ax[1].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値\n",
    "Y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測の形\n",
    "Y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測の可視化\n",
    "plt.imshow(Y_test_pred[:10], cmap='gray', interpolation='nearest', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データを可視化（最初の10文字）\n",
    "fig, ax = plt.subplots(1, 10, figsize=(10, 2))\n",
    "\n",
    "for ii in range(10):\n",
    "    ax[ii].imshow(X_test[ii].reshape(28, 28), cmap='gray')\n",
    "    ax[ii].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y_test_pred[:40], cmap='gray', interpolation='nearest', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測の可視化\n",
    "plt.imshow(Y_test_pred[30:40], cmap='gray', interpolation='nearest', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データを可視化（30~39文字目までの10文字）\n",
    "fig, ax = plt.subplots(1, 10, figsize=(10, 2))\n",
    "\n",
    "for ii in range(10):\n",
    "    ax[ii].imshow(X_test[ii+30].reshape(28, 28), cmap='gray')\n",
    "    ax[ii].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## もし機械学習に興味を持ったら\n",
    "\n",
    "+ PyData.Okinawa の過去資料を漁る (機械学習に関連する知識と基盤を固める)\n",
    "+ https://python-beginners-okinawa.connpass.com/event/127905/ ベイズの勉強会に参加する\n",
    "+ データ分析の競技プログラミングに参加する\n",
    "    + Kaggle\n",
    "    + SIGNATE\n",
    "+ 最近のトレンドを追う\n",
    "    + SSD + HoloV3 ( 物体検知 )\n",
    "    + GAN ( 画像生成 )\n",
    "    + BERT, Self-Attention ( 自然言語処理 )\n",
    "    + CNN, RNN ( 深層学習 )\n",
    "    + PyTorch あたりで触れることが出来る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
